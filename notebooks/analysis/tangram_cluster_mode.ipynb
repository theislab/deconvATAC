{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/storage/miniconda3/envs/cell2loc_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mudata as mu\n",
    "from deconvatac.tl import tangram\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seml\n",
    "import pandas as pd\n",
    "import glob\n",
    "import deconvatac as de\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tangram on Cluster Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentWrapper:\n",
    "    \"\"\"\n",
    "    A simple wrapper around a sacred experiment, making use of sacred's captured functions with prefixes.\n",
    "    This allows a modular design of the configuration, where certain sub-dictionaries (e.g., \"data\") are parsed by\n",
    "    specific method. This avoids having one large \"main\" function which takes all parameters as input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_all=True):\n",
    "        if init_all:\n",
    "            self.init_all()\n",
    "\n",
    "    def init_dataset(self, mdata_spatial_path, mdata_reference_path, var_HVF_column, labels_key, modality):\n",
    "\n",
    "        self.spatial_path = mdata_spatial_path\n",
    "        self.adata_spatial = mu.read_h5mu(mdata_spatial_path).mod[modality]\n",
    "        self.adata_reference = mu.read_h5mu(mdata_reference_path).mod[modality]\n",
    "        # subset on HVFs\n",
    "        self.adata_spatial = self.adata_spatial[:, self.adata_reference.var[var_HVF_column]]\n",
    "        self.adata_reference = self.adata_reference[:, self.adata_reference.var[var_HVF_column]]\n",
    "\n",
    "        self.modality = modality\n",
    "        self.labels_key = labels_key\n",
    "        self.var_HVF_column = var_HVF_column\n",
    "\n",
    "    def init_method(self, method_id):\n",
    "        self.method_id = method_id\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_dataset()\n",
    "        self.init_method()\n",
    "\n",
    "    def run(self, output_path):\n",
    "\n",
    "        dataset = self.spatial_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        dataset_var_column = dataset + \"_\" + self.var_HVF_column\n",
    "        output_path = output_path + self.modality + \"/\" + dataset_var_column\n",
    "\n",
    "        tangram(\n",
    "            adata_spatial=self.adata_spatial,\n",
    "            adata_ref=self.adata_reference,\n",
    "            labels_key=self.labels_key,\n",
    "            run_rank_genes=False,\n",
    "            result_path=output_path,\n",
    "            device=\"cuda:0\",\n",
    "            num_epochs=1000,\n",
    "            **{\"cluster_label\": self.labels_key, \"mode\": \"clusters\"},\n",
    "        )\n",
    "\n",
    "        results = {\n",
    "            \"result_path\": output_path + \"/tangram_ct_pred.csv\",\n",
    "            \"dataset\": dataset,\n",
    "            \"modality\": self.modality,\n",
    "            \"var_HVF_column\": self.var_HVF_column,\n",
    "        }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tangram(ref_path, spatial_path, modality): \n",
    "    mdata_reference_path = ref_path\n",
    "    mdata_spatial_path = spatial_path\n",
    "    method_id =  \"Tangram\"\n",
    "    output_path =  \"/vol/storage/data/deconvolution_results/test2/cluster_mode/\" \n",
    "    labels_key = \"cell_type\"\n",
    "    modality = modality\n",
    "    var_HVF_column = \"highly_variable\"\n",
    "    ex = ExperimentWrapper(init_all=False)\n",
    "    ex.init_dataset(mdata_spatial_path, mdata_reference_path, var_HVF_column, labels_key, modality)\n",
    "    ex.init_method(method_id)\n",
    "    ex.run(output_path)\n",
    "    if modality == \"atac\": \n",
    "        var_HVF_column = \"highly_accessible\"\n",
    "        ex = ExperimentWrapper(init_all=False)\n",
    "        ex.init_dataset(mdata_spatial_path, mdata_reference_path, var_HVF_column, labels_key, modality)\n",
    "        ex.init_method(method_id)\n",
    "        ex.run(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heart Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_paths = \"/vol/storage/data/simulations/human_cardiac_niches.h5mu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_paths = [\"/vol/storage/data/simulations/Heart_1.h5mu\", \"/vol/storage/data/simulations/Heart_2.h5mu\", \n",
    "                 \"/vol/storage/data/simulations/Heart_3.h5mu\", \"/vol/storage/data/simulations/Heart_4.h5mu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(spatial_paths)): \n",
    "    run_tangram(ref_paths, spatial_paths[i], \"rna\")\n",
    "    run_tangram(ref_paths, spatial_paths[i], \"atac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Russell Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = \"/vol/storage/data/simulations/russel_ref.h5mu\"\n",
    "spatial_path = \"/vol/storage/data/simulations/russell_250.h5mu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tangram(ref_path, spatial_path, \"rna\")\n",
    "run_tangram(ref_path, spatial_path, \"atac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_paths = \"/vol/storage/data/simulations/human_developing_cerebral_cortex.h5mu\"\n",
    "spatial_paths = [\"/vol/storage/data/simulations/Brain_1.h5mu\", \"/vol/storage/data/simulations/Brain_2.h5mu\", \n",
    "                 \"/vol/storage/data/simulations/Brain_3.h5mu\", \"/vol/storage/data/simulations/Brain_4.h5mu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(spatial_paths)): \n",
    "    run_tangram(ref_paths, spatial_paths[i], \"rna\")\n",
    "    run_tangram(ref_paths, spatial_paths[i], \"atac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportions(adata):\n",
    "    df = pd.DataFrame(adata.obsm[\"proportions\"], columns=adata.uns[\"proportion_names\"], index=adata.obs_names)\n",
    "    return df\n",
    "\n",
    "def load_table(path, index_col):\n",
    "    res = pd.read_csv(path, index_col=index_col)\n",
    "    if \"q05cell_abundance_w_sf_\" in res.columns[0]:\n",
    "        res.columns = res.columns.to_series().str.split(\"q05cell_abundance_w_sf_\", expand=True).loc[:, 1].values\n",
    "    elif \"meanscell_abundance_w_sf_\" in res.columns[0]:\n",
    "        res.columns = res.columns.to_series().str.split(\"meanscell_abundance_w_sf_\", expand=True).loc[:, 1].values\n",
    "    if res.index[0] != 0:\n",
    "        res.index = res.index.astype(int) - 1\n",
    "    res.index = res.index.astype(str)\n",
    "    if \"cell_ID\" in res.columns:\n",
    "        res.drop(\"cell_ID\", axis=1, inplace=True)\n",
    "    res = res.div(res.sum(axis=1), axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(data_paths,  modalities, mapping_dict, results_path):\n",
    "    df = [pd.DataFrame({'path': glob.glob(os.path.join(data_paths[0], modality, \"*\", \"*\"))}) for modality in modalities]\n",
    "    df = pd.concat(df)\n",
    "    df[['modality', 'dataset_features']] = df['path'].str.split('/', expand=True).iloc[:, 7:-1]\n",
    "    df[['method']] = \"tangram\"\n",
    "    df['dataset'] = df['dataset_features'].str.rsplit(\"_\", n=2).str[0]\n",
    "    df[\"features\"] = df[\"dataset_features\"].str.split(\"_\", n=2).str[-1]\n",
    "    df[\"mdata_spatial_path\"] = df['dataset'].map(mapping_dict)\n",
    "\n",
    "    jsd = []\n",
    "    rmse = []\n",
    "    for _, row in tqdm.tqdm(df.iterrows()):\n",
    "        # load ground truth\n",
    "        target_adata = mu.read(row[\"mdata_spatial_path\"])\n",
    "        targets = get_proportions(target_adata[row[\"modality\"]])\n",
    "\n",
    "        # load table\n",
    "        predictions = load_table(row[\"path\"], index_col=(None if row[\"method\"] == \"moscot\" else 0))\n",
    "        missing_cell_types = [cell_type for cell_type in targets.columns if cell_type not in predictions.columns]\n",
    "        predictions = predictions.assign(**dict.fromkeys(missing_cell_types, 0))\n",
    "        predictions = predictions.loc[targets.index, targets.columns]\n",
    "        jsd.append(de.tl.jsd(predictions, targets))\n",
    "        rmse.append(de.tl.rmse(predictions, targets))\n",
    "    df[\"jsd\"] = jsd\n",
    "    df[\"rmse\"] = rmse\n",
    "    \n",
    "    df.to_csv(results_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    \"russell_250\": \"/vol/storage/data/simulations/russell_250.h5mu\",\n",
    "    \"Heart_1\": \"/vol/storage/data/simulations/Heart_1.h5mu\",\n",
    "    \"Heart_2\": \"/vol/storage/data/simulations/Heart_2.h5mu\",\n",
    "    \"Heart_3\": \"/vol/storage/data/simulations/Heart_3.h5mu\",\n",
    "    \"Heart_4\": \"/vol/storage/data/simulations/Heart_4.h5mu\",\n",
    "    \"Brain_1\": \"/vol/storage/data/simulations/Brain_1.h5mu\",\n",
    "    \"Brain_2\": \"/vol/storage/data/simulations/Brain_2.h5mu\",\n",
    "    \"Brain_3\": \"/vol/storage/data/simulations/Brain_3.h5mu\",\n",
    "    \"Brain_4\": \"/vol/storage/data/simulations/Brain_4.h5mu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = [\"/vol/storage/data/deconvolution_results/test2/cluster_mode\"]\n",
    "methods = [\"tangram\"]\n",
    "modalities = [\"atac\", \"rna\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [04:35, 10.19s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluate_results(data_paths=data_path, modalities=modalities, mapping_dict=mapping_dict, results_path=\"results_table_cluster_mode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>modality</th>\n",
       "      <th>dataset_features</th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>features</th>\n",
       "      <th>mdata_spatial_path</th>\n",
       "      <th>jsd</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_1_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_1</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_1.h5mu</td>\n",
       "      <td>0.759367</td>\n",
       "      <td>0.185936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_3_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_3</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_3.h5mu</td>\n",
       "      <td>0.691354</td>\n",
       "      <td>0.169234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>russell_250_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>russell_250</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/russell_250.h5mu</td>\n",
       "      <td>0.494151</td>\n",
       "      <td>0.183020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_2_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_2</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_2.h5mu</td>\n",
       "      <td>0.568031</td>\n",
       "      <td>0.102282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>russell_250_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>russell_250</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/russell_250.h5mu</td>\n",
       "      <td>0.508469</td>\n",
       "      <td>0.181423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path modality  \\\n",
       "0  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "1  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "2  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "3  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "4  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "\n",
       "                dataset_features   method      dataset           features  \\\n",
       "0      Brain_1_highly_accessible  tangram      Brain_1  highly_accessible   \n",
       "1      Heart_3_highly_accessible  tangram      Heart_3  highly_accessible   \n",
       "2    russell_250_highly_variable  tangram  russell_250    highly_variable   \n",
       "3        Brain_2_highly_variable  tangram      Brain_2    highly_variable   \n",
       "4  russell_250_highly_accessible  tangram  russell_250  highly_accessible   \n",
       "\n",
       "                               mdata_spatial_path       jsd      rmse  \n",
       "0      /vol/storage/data/simulations/Brain_1.h5mu  0.759367  0.185936  \n",
       "1      /vol/storage/data/simulations/Heart_3.h5mu  0.691354  0.169234  \n",
       "2  /vol/storage/data/simulations/russell_250.h5mu  0.494151  0.183020  \n",
       "3      /vol/storage/data/simulations/Brain_2.h5mu  0.568031  0.102282  \n",
       "4  /vol/storage/data/simulations/russell_250.h5mu  0.508469  0.181423  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('results_table_cluster_mode.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>modality</th>\n",
       "      <th>dataset_features</th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>features</th>\n",
       "      <th>mdata_spatial_path</th>\n",
       "      <th>jsd</th>\n",
       "      <th>rmse</th>\n",
       "      <th>dataset2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_1_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_1</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_1.h5mu</td>\n",
       "      <td>0.759367</td>\n",
       "      <td>0.185936</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_3_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_3</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_3.h5mu</td>\n",
       "      <td>0.691354</td>\n",
       "      <td>0.169234</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>russell_250_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>russell_250</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/russell_250.h5mu</td>\n",
       "      <td>0.494151</td>\n",
       "      <td>0.183020</td>\n",
       "      <td>russell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_2_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_2</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_2.h5mu</td>\n",
       "      <td>0.568031</td>\n",
       "      <td>0.102282</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>russell_250_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>russell_250</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/russell_250.h5mu</td>\n",
       "      <td>0.508469</td>\n",
       "      <td>0.181423</td>\n",
       "      <td>russell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_4_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_4</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_4.h5mu</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.151976</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_3_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_3</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_3.h5mu</td>\n",
       "      <td>0.581553</td>\n",
       "      <td>0.124625</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_1_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_1</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_1.h5mu</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_1_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_1</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_1.h5mu</td>\n",
       "      <td>0.924113</td>\n",
       "      <td>0.241885</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_3_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_3</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_3.h5mu</td>\n",
       "      <td>0.552594</td>\n",
       "      <td>0.113441</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_4_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_4</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_4.h5mu</td>\n",
       "      <td>0.722076</td>\n",
       "      <td>0.177725</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_2_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_2</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_2.h5mu</td>\n",
       "      <td>0.678814</td>\n",
       "      <td>0.154144</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_3_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_3</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_3.h5mu</td>\n",
       "      <td>0.630467</td>\n",
       "      <td>0.149514</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_4_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_4</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_4.h5mu</td>\n",
       "      <td>0.778559</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_2_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_2</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_2.h5mu</td>\n",
       "      <td>0.624794</td>\n",
       "      <td>0.135193</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_1_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_1</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_1.h5mu</td>\n",
       "      <td>0.904940</td>\n",
       "      <td>0.229489</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_4_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_4</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_4.h5mu</td>\n",
       "      <td>0.612835</td>\n",
       "      <td>0.140068</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Brain_2_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_2</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_2.h5mu</td>\n",
       "      <td>0.601967</td>\n",
       "      <td>0.114646</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>russell_250_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>russell_250</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/russell_250.h5mu</td>\n",
       "      <td>0.462513</td>\n",
       "      <td>0.166592</td>\n",
       "      <td>russell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>Brain_2_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_2</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_2.h5mu</td>\n",
       "      <td>0.487398</td>\n",
       "      <td>0.075268</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>Brain_1_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_1</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_1.h5mu</td>\n",
       "      <td>0.759699</td>\n",
       "      <td>0.178165</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>Brain_3_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_3</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_3.h5mu</td>\n",
       "      <td>0.433379</td>\n",
       "      <td>0.079660</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>Heart_4_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_4</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_4.h5mu</td>\n",
       "      <td>0.571554</td>\n",
       "      <td>0.127264</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>Heart_3_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_3</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_3.h5mu</td>\n",
       "      <td>0.463121</td>\n",
       "      <td>0.099352</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>Heart_2_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_2</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_2.h5mu</td>\n",
       "      <td>0.490643</td>\n",
       "      <td>0.087696</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>Heart_1_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_1</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Heart_1.h5mu</td>\n",
       "      <td>0.780529</td>\n",
       "      <td>0.187021</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>rna</td>\n",
       "      <td>Brain_4_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Brain_4</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/Brain_4.h5mu</td>\n",
       "      <td>0.531902</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>Brain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path modality  \\\n",
       "0   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "1   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "2   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "3   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "4   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "5   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "6   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "7   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "8   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "9   /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "10  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "11  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "12  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "13  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "14  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "15  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "16  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "17  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "0   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "1   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "2   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "3   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "4   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "5   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "6   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "7   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "8   /vol/storage/data/deconvolution_results/test2/...      rna   \n",
       "\n",
       "                 dataset_features   method      dataset           features  \\\n",
       "0       Brain_1_highly_accessible  tangram      Brain_1  highly_accessible   \n",
       "1       Heart_3_highly_accessible  tangram      Heart_3  highly_accessible   \n",
       "2     russell_250_highly_variable  tangram  russell_250    highly_variable   \n",
       "3         Brain_2_highly_variable  tangram      Brain_2    highly_variable   \n",
       "4   russell_250_highly_accessible  tangram  russell_250  highly_accessible   \n",
       "5       Brain_4_highly_accessible  tangram      Brain_4  highly_accessible   \n",
       "6       Brain_3_highly_accessible  tangram      Brain_3  highly_accessible   \n",
       "7         Brain_1_highly_variable  tangram      Brain_1    highly_variable   \n",
       "8       Heart_1_highly_accessible  tangram      Heart_1  highly_accessible   \n",
       "9         Brain_3_highly_variable  tangram      Brain_3    highly_variable   \n",
       "10        Heart_4_highly_variable  tangram      Heart_4    highly_variable   \n",
       "11      Heart_2_highly_accessible  tangram      Heart_2  highly_accessible   \n",
       "12        Heart_3_highly_variable  tangram      Heart_3    highly_variable   \n",
       "13      Heart_4_highly_accessible  tangram      Heart_4  highly_accessible   \n",
       "14        Heart_2_highly_variable  tangram      Heart_2    highly_variable   \n",
       "15        Heart_1_highly_variable  tangram      Heart_1    highly_variable   \n",
       "16        Brain_4_highly_variable  tangram      Brain_4    highly_variable   \n",
       "17      Brain_2_highly_accessible  tangram      Brain_2  highly_accessible   \n",
       "0     russell_250_highly_variable  tangram  russell_250    highly_variable   \n",
       "1         Brain_2_highly_variable  tangram      Brain_2    highly_variable   \n",
       "2         Brain_1_highly_variable  tangram      Brain_1    highly_variable   \n",
       "3         Brain_3_highly_variable  tangram      Brain_3    highly_variable   \n",
       "4         Heart_4_highly_variable  tangram      Heart_4    highly_variable   \n",
       "5         Heart_3_highly_variable  tangram      Heart_3    highly_variable   \n",
       "6         Heart_2_highly_variable  tangram      Heart_2    highly_variable   \n",
       "7         Heart_1_highly_variable  tangram      Heart_1    highly_variable   \n",
       "8         Brain_4_highly_variable  tangram      Brain_4    highly_variable   \n",
       "\n",
       "                                mdata_spatial_path       jsd      rmse  \\\n",
       "0       /vol/storage/data/simulations/Brain_1.h5mu  0.759367  0.185936   \n",
       "1       /vol/storage/data/simulations/Heart_3.h5mu  0.691354  0.169234   \n",
       "2   /vol/storage/data/simulations/russell_250.h5mu  0.494151  0.183020   \n",
       "3       /vol/storage/data/simulations/Brain_2.h5mu  0.568031  0.102282   \n",
       "4   /vol/storage/data/simulations/russell_250.h5mu  0.508469  0.181423   \n",
       "5       /vol/storage/data/simulations/Brain_4.h5mu  0.649891  0.151976   \n",
       "6       /vol/storage/data/simulations/Brain_3.h5mu  0.581553  0.124625   \n",
       "7       /vol/storage/data/simulations/Brain_1.h5mu  0.755814  0.183469   \n",
       "8       /vol/storage/data/simulations/Heart_1.h5mu  0.924113  0.241885   \n",
       "9       /vol/storage/data/simulations/Brain_3.h5mu  0.552594  0.113441   \n",
       "10      /vol/storage/data/simulations/Heart_4.h5mu  0.722076  0.177725   \n",
       "11      /vol/storage/data/simulations/Heart_2.h5mu  0.678814  0.154144   \n",
       "12      /vol/storage/data/simulations/Heart_3.h5mu  0.630467  0.149514   \n",
       "13      /vol/storage/data/simulations/Heart_4.h5mu  0.778559  0.197400   \n",
       "14      /vol/storage/data/simulations/Heart_2.h5mu  0.624794  0.135193   \n",
       "15      /vol/storage/data/simulations/Heart_1.h5mu  0.904940  0.229489   \n",
       "16      /vol/storage/data/simulations/Brain_4.h5mu  0.612835  0.140068   \n",
       "17      /vol/storage/data/simulations/Brain_2.h5mu  0.601967  0.114646   \n",
       "0   /vol/storage/data/simulations/russell_250.h5mu  0.462513  0.166592   \n",
       "1       /vol/storage/data/simulations/Brain_2.h5mu  0.487398  0.075268   \n",
       "2       /vol/storage/data/simulations/Brain_1.h5mu  0.759699  0.178165   \n",
       "3       /vol/storage/data/simulations/Brain_3.h5mu  0.433379  0.079660   \n",
       "4       /vol/storage/data/simulations/Heart_4.h5mu  0.571554  0.127264   \n",
       "5       /vol/storage/data/simulations/Heart_3.h5mu  0.463121  0.099352   \n",
       "6       /vol/storage/data/simulations/Heart_2.h5mu  0.490643  0.087696   \n",
       "7       /vol/storage/data/simulations/Heart_1.h5mu  0.780529  0.187021   \n",
       "8       /vol/storage/data/simulations/Brain_4.h5mu  0.531902  0.112547   \n",
       "\n",
       "   dataset2  \n",
       "0     Brain  \n",
       "1     Heart  \n",
       "2   russell  \n",
       "3     Brain  \n",
       "4   russell  \n",
       "5     Brain  \n",
       "6     Brain  \n",
       "7     Brain  \n",
       "8     Heart  \n",
       "9     Brain  \n",
       "10    Heart  \n",
       "11    Heart  \n",
       "12    Heart  \n",
       "13    Heart  \n",
       "14    Heart  \n",
       "15    Heart  \n",
       "16    Brain  \n",
       "17    Brain  \n",
       "0   russell  \n",
       "1     Brain  \n",
       "2     Brain  \n",
       "3     Brain  \n",
       "4     Heart  \n",
       "5     Heart  \n",
       "6     Heart  \n",
       "7     Heart  \n",
       "8     Brain  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dataset2\"] = df[\"dataset\"].str.split('_', n=1, expand=True).iloc[:,0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method   dataset2  features           modality\n",
       "tangram  Brain     highly_accessible  atac        0.648194\n",
       "                   highly_variable    atac        0.622318\n",
       "                                      rna         0.553095\n",
       "         Heart     highly_accessible  atac        0.768210\n",
       "                   highly_variable    atac        0.720569\n",
       "                                      rna         0.576462\n",
       "         russell   highly_accessible  atac        0.508469\n",
       "                   highly_variable    atac        0.494151\n",
       "                                      rna         0.462513\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['method', \"dataset2\",'features', 'modality'])[['jsd']].mean().sum(axis=1)#.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method   features           modality\n",
       "tangram  highly_accessible  atac        0.708202\n",
       "         highly_variable    atac        0.671444\n",
       "                            rna         0.564778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"dataset2\"] != \"russell\"].groupby(['method','features', 'modality'])[['jsd']].mean().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method   features           modality\n",
       "tangram  highly_accessible  atac        0.167481\n",
       "         highly_variable    atac        0.153898\n",
       "                            rna         0.118372\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"dataset2\"] != \"russell\"].groupby(['method','features', 'modality'])[['rmse']].mean().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method   dataset2  features           modality\n",
       "tangram  Brain     highly_accessible  atac        0.144296\n",
       "                   highly_variable    atac        0.134815\n",
       "                                      rna         0.111410\n",
       "         Heart     highly_accessible  atac        0.190666\n",
       "                   highly_variable    atac        0.172980\n",
       "                                      rna         0.125333\n",
       "         russell   highly_accessible  atac        0.181423\n",
       "                   highly_variable    atac        0.183020\n",
       "                                      rna         0.166592\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['method', \"dataset2\", 'features', 'modality'])[['rmse']].mean().sum(axis=1)#.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell2loc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

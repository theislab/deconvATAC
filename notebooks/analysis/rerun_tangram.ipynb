{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/storage/miniconda3/envs/cell2loc_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import mudata as mu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import deconvatac as de\n",
    "from deconvatac.tl import tangram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentWrapper:\n",
    "    \"\"\"\n",
    "    A simple wrapper around a sacred experiment, making use of sacred's captured functions with prefixes.\n",
    "    This allows a modular design of the configuration, where certain sub-dictionaries (e.g., \"data\") are parsed by\n",
    "    specific method. This avoids having one large \"main\" function which takes all parameters as input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_all=True):\n",
    "        if init_all:\n",
    "            self.init_all()\n",
    "\n",
    "    def init_dataset(self, mdata_spatial_path, mdata_reference_path, var_HVF_column, labels_key, modality):\n",
    "\n",
    "        self.spatial_path = mdata_spatial_path\n",
    "        self.adata_spatial = mu.read_h5mu(mdata_spatial_path).mod[modality]\n",
    "        self.adata_reference = mu.read_h5mu(mdata_reference_path).mod[modality]\n",
    "        # subset on HVFs\n",
    "        self.adata_spatial = self.adata_spatial[:, self.adata_reference.var[var_HVF_column]]\n",
    "        self.adata_reference = self.adata_reference[:, self.adata_reference.var[var_HVF_column]]\n",
    "\n",
    "        self.modality = modality\n",
    "        self.labels_key = labels_key\n",
    "        self.var_HVF_column = var_HVF_column\n",
    "\n",
    "    def init_method(self, method_id):\n",
    "        self.method_id = method_id\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_dataset()\n",
    "        self.init_method()\n",
    "\n",
    "    def run(self, output_path):\n",
    "\n",
    "        dataset = self.spatial_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        dataset_var_column = dataset + \"_\" + self.var_HVF_column\n",
    "        output_path = output_path + self.modality + \"/\" + dataset_var_column\n",
    "\n",
    "        tangram(\n",
    "            adata_spatial=self.adata_spatial,\n",
    "            adata_ref=self.adata_reference,\n",
    "            labels_key=self.labels_key,\n",
    "            run_rank_genes=False,\n",
    "            result_path=output_path,\n",
    "            device=\"cuda:0\",\n",
    "            num_epochs=1000,\n",
    "        )\n",
    "\n",
    "        results = {\n",
    "            \"result_path\": output_path + \"/tangram_ct_pred.csv\",\n",
    "            \"dataset\": dataset,\n",
    "            \"modality\": self.modality,\n",
    "            \"var_HVF_column\": self.var_HVF_column,\n",
    "        }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference(parquet, ref_path=None, power=None): \n",
    "    if power is None: \n",
    "        sample_cells = pd.read_parquet(parquet)\n",
    "        ref = mu.read_h5mu(\"/vol/storage/submission_data/data/human_cardiac_niches.h5mu\")\n",
    "        cell_ids = np.concatenate(sample_cells['cell_id'].values)\n",
    "        ref = ref[np.unique(cell_ids)]\n",
    "        print(ref)\n",
    "        ref.write(ref_path)\n",
    "    else: \n",
    "        sample_cells = pd.read_parquet(parquet)\n",
    "        cell_ids = np.unique(np.concatenate(sample_cells['cell_id'].values))\n",
    "        ref = mu.read_h5mu(\"/vol/storage/submission_data/data/human_cardiac_niches.h5mu\")\n",
    "        ids = list(set(ref.obs.index) - set(np.unique(cell_ids)))\n",
    "        for i in range(len(power)):\n",
    "            n_draw = len(cell_ids)*2**power[i]\n",
    "            if n_draw > len(ids):\n",
    "                n_draw = len(ids)\n",
    "            drawn_ids = np.random.choice(ids, n_draw, replace=False)\n",
    "            resulting_ids = np.concatenate([cell_ids, drawn_ids])\n",
    "            ref_new = ref[resulting_ids].copy()\n",
    "            print(ref_new)\n",
    "            ref_new.write(\"/vol/storage/submission_data/data/simulations/test/power\" + str(power[i]) + \"/\"+ parquet.split(\"/\")[-1].split(\".\")[0] + \"_ref.h5mu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquets = [\"/vol/storage/data/simulations/test/Heart_1.pq\", \"/vol/storage/data/simulations/test/Heart_2.pq\", \n",
    "            \"/vol/storage/data/simulations/test/Heart_3.pq\", \"/vol/storage/data/simulations/test/Heart_4.pq\"]\n",
    "ref_paths = [\"/vol/storage/data/simulations/test/Heart1_ref.h5mu\", \"/vol/storage/data/simulations/test/Heart2_ref.h5mu\"\n",
    "             , \"/vol/storage/data/simulations/test/Heart3_ref.h5mu\", \"/vol/storage/data/simulations/test/Heart4_ref.h5mu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create references without drawn cell ids: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(parquets)):\n",
    "    create_reference(parquets[i], ref_paths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create references with drawn cell ids: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = [0,1,2,3]\n",
    "for i in range(len(parquets)):\n",
    "    create_reference(parquets[i], power=power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Tangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tangram(ref_path, spatial_path, modality): \n",
    "    mdata_reference_path = ref_path\n",
    "    mdata_spatial_path = spatial_path\n",
    "    method_id =  \"Tangram\"\n",
    "    output_path =  \"/vol/storage/data/deconvolution_results/test2/\"\n",
    "    if \"power\" in ref_path.split(\"/\")[-2]:\n",
    "        output_path =  \"/vol/storage/data/deconvolution_results/test2/\" + ref_path.split(\"/\")[-2] + \"/\"\n",
    "    labels_key = \"cell_type\"\n",
    "    modality = modality\n",
    "    var_HVF_column = \"highly_variable\"\n",
    "    ex = ExperimentWrapper(init_all=False)\n",
    "    ex.init_dataset(mdata_spatial_path, mdata_reference_path, var_HVF_column, labels_key, modality)\n",
    "    ex.init_method(method_id)\n",
    "    ex.run(output_path)\n",
    "    if modality == \"atac\": \n",
    "        var_HVF_column = \"highly_accessible\"\n",
    "        ex = ExperimentWrapper(init_all=False)\n",
    "        ex.init_dataset(mdata_spatial_path, mdata_reference_path, var_HVF_column, labels_key, modality)\n",
    "        ex.init_method(method_id)\n",
    "        ex.run(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_paths = [\"/vol/storage/data/simulations/test/Heart_1.h5mu\", \"/vol/storage/data/simulations/test/Heart_2.h5mu\", \n",
    "                 \"/vol/storage/data/simulations/test/Heart_3.h5mu\", \"/vol/storage/data/simulations/test/Heart_4.h5mu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(spatial_paths)): \n",
    "    run_tangram(ref_paths[i], spatial_paths[i], \"rna\")\n",
    "    run_tangram(ref_paths[i], spatial_paths[i], \"atac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = [0,1,2,3]\n",
    "for j in range(len(spatial_paths)):\n",
    "    for i in range(len(power)): \n",
    "        ref_path = \"/vol/storage/data/simulations/test/power\" + str(power[i]) + \"/\"+ spatial_paths[j].split(\"/\")[-1].split(\".\")[0] + \"_ref.h5mu\"\n",
    "        print(ref_path, spatial_paths[j])\n",
    "        run_tangram(ref_path, spatial_paths[j], \"rna\")\n",
    "        run_tangram(ref_path, spatial_paths[j], \"atac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportions(adata):\n",
    "    df = pd.DataFrame(adata.obsm[\"proportions\"], columns=adata.uns[\"proportion_names\"], index=adata.obs_names)\n",
    "    return df\n",
    "\n",
    "def load_table(path, index_col):\n",
    "    res = pd.read_csv(path, index_col=index_col)\n",
    "    if \"q05cell_abundance_w_sf_\" in res.columns[0]:\n",
    "        res.columns = res.columns.to_series().str.split(\"q05cell_abundance_w_sf_\", expand=True).loc[:, 1].values\n",
    "    elif \"meanscell_abundance_w_sf_\" in res.columns[0]:\n",
    "        res.columns = res.columns.to_series().str.split(\"meanscell_abundance_w_sf_\", expand=True).loc[:, 1].values\n",
    "    if res.index[0] != 0:\n",
    "        res.index = res.index.astype(int) - 1\n",
    "    res.index = res.index.astype(str)\n",
    "    if \"cell_ID\" in res.columns:\n",
    "        res.drop(\"cell_ID\", axis=1, inplace=True)\n",
    "    res = res.div(res.sum(axis=1), axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(data_paths,  modalities, mapping_dict, results_path):\n",
    "    if \"power\" not in data_paths[0]:\n",
    "        df = [pd.DataFrame({'path': glob.glob(os.path.join(data_paths[0], modality, \"*\", \"*\"))}) for modality in modalities]\n",
    "        df = pd.concat(df)\n",
    "        df[['modality', 'dataset_features']] = df['path'].str.split('/', expand=True).iloc[:, 6:-1]\n",
    "    else: \n",
    "        df = [pd.DataFrame({'path': glob.glob(os.path.join(data_path, modality, \"*\", \"*\"))}) for data_path in data_paths for modality in modalities]\n",
    "        df = pd.concat(df)\n",
    "        df[['power','modality', 'dataset_features']] = df['path'].str.split('/', expand=True).iloc[:, 6:-1]\n",
    "    df[['method']] = \"tangram\"\n",
    "    df['dataset'] = df['dataset_features'].str.rsplit(\"_\", n=2).str[0]\n",
    "    df[\"features\"] = df[\"dataset_features\"].str.split(\"_\", n=2).str[-1]\n",
    "    df[\"mdata_spatial_path\"] = df['dataset'].map(mapping_dict)\n",
    "\n",
    "    jsd = []\n",
    "    rmse = []\n",
    "    for _, row in tqdm.tqdm(df.iterrows()):\n",
    "        # load ground truth\n",
    "        target_adata = mu.read(row[\"mdata_spatial_path\"])\n",
    "        targets = get_proportions(target_adata[row[\"modality\"]])\n",
    "\n",
    "        # load table\n",
    "        predictions = load_table(row[\"path\"], index_col=(None if row[\"method\"] == \"moscot\" else 0))\n",
    "        missing_cell_types = [cell_type for cell_type in targets.columns if cell_type not in predictions.columns]\n",
    "        predictions = predictions.assign(**dict.fromkeys(missing_cell_types, 0))\n",
    "        predictions = predictions.loc[targets.index, targets.columns]\n",
    "        jsd.append(de.tl.jsd(predictions, targets))\n",
    "        rmse.append(de.tl.rmse(predictions, targets))\n",
    "    df[\"jsd\"] = jsd\n",
    "    df[\"rmse\"] = rmse\n",
    "    \n",
    "    df.to_csv(results_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    \"russell_250\": \"/vol/storage/data/simulations/test/russell_250.h5mu\",\n",
    "    \"Heart_1\": \"/vol/storage/data/simulations/test/Heart_1.h5mu\",\n",
    "    \"Heart_2\": \"/vol/storage/data/simulations/test/Heart_2.h5mu\",\n",
    "    \"Heart_3\": \"/vol/storage/data/simulations/test/Heart_3.h5mu\",\n",
    "    \"Heart_4\": \"/vol/storage/data/simulations/test/Heart_4.h5mu\",\n",
    "    \"Brain_1\": \"/vol/storage/data/simulations/test/Brain_1.h5mu\",\n",
    "    \"Brain_2\": \"/vol/storage/data/simulations/test/Brain_2.h5mu\",\n",
    "    \"Brain_3\": \"/vol/storage/data/simulations/test/Brain_3.h5mu\",\n",
    "    \"Brain_4\": \"/vol/storage/data/simulations/test/Brain_4.h5mu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = [\"/vol/storage/data/deconvolution_results/test2\"]\n",
    "methods = [\"tangram\"]\n",
    "modalities = [\"atac\", \"rna\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:23,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluate_results(data_paths=data_path, modalities=modalities, mapping_dict=mapping_dict, results_path=\"../results/tables/results_table_tangram_no_draw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>modality</th>\n",
       "      <th>dataset_features</th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>features</th>\n",
       "      <th>mdata_spatial_path</th>\n",
       "      <th>jsd</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_3_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_3</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_3.h5mu</td>\n",
       "      <td>0.326849</td>\n",
       "      <td>0.068327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_1_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_1</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_1.h5mu</td>\n",
       "      <td>0.442848</td>\n",
       "      <td>0.179567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_4_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_4</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_4.h5mu</td>\n",
       "      <td>0.401321</td>\n",
       "      <td>0.096223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_2_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_2</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_2.h5mu</td>\n",
       "      <td>0.327318</td>\n",
       "      <td>0.061107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_3_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_3</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_3.h5mu</td>\n",
       "      <td>0.325744</td>\n",
       "      <td>0.065920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path modality  \\\n",
       "0  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "1  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "2  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "3  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "4  /vol/storage/data/deconvolution_results/test2/...     atac   \n",
       "\n",
       "            dataset_features   method  dataset           features  \\\n",
       "0  Heart_3_highly_accessible  tangram  Heart_3  highly_accessible   \n",
       "1  Heart_1_highly_accessible  tangram  Heart_1  highly_accessible   \n",
       "2    Heart_4_highly_variable  tangram  Heart_4    highly_variable   \n",
       "3  Heart_2_highly_accessible  tangram  Heart_2  highly_accessible   \n",
       "4    Heart_3_highly_variable  tangram  Heart_3    highly_variable   \n",
       "\n",
       "                                mdata_spatial_path       jsd      rmse  \n",
       "0  /vol/storage/data/simulations/test/Heart_3.h5mu  0.326849  0.068327  \n",
       "1  /vol/storage/data/simulations/test/Heart_1.h5mu  0.442848  0.179567  \n",
       "2  /vol/storage/data/simulations/test/Heart_4.h5mu  0.401321  0.096223  \n",
       "3  /vol/storage/data/simulations/test/Heart_2.h5mu  0.327318  0.061107  \n",
       "4  /vol/storage/data/simulations/test/Heart_3.h5mu  0.325744  0.065920  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../results/tables/results_table_tangram_no_draw.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method   features           modality\n",
       "tangram  highly_variable    rna         0.369342\n",
       "         highly_accessible  atac        0.372315\n",
       "         highly_variable    atac        0.374485\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['method', 'features', 'modality'])[['jsd']].mean().sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method   features           modality\n",
       "tangram  highly_variable    rna         0.097772\n",
       "                            atac        0.100740\n",
       "         highly_accessible  atac        0.101655\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['method', 'features', 'modality'])[['rmse']].mean().sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\"/vol/storage/data/deconvolution_results/test2/power0/\", \"/vol/storage/data/deconvolution_results/test2/power1/\",\n",
    "                \"/vol/storage/data/deconvolution_results/test2/power2/\", \"/vol/storage/data/deconvolution_results/test2/power3/\"]\n",
    "methods = [\"tangram\"]\n",
    "modalities = [\"atac\", \"rna\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [01:35,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluate_results(data_paths=data_paths, modalities=modalities, mapping_dict=mapping_dict, results_path=\"../results/tables/results_table_tangram_draw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>power</th>\n",
       "      <th>modality</th>\n",
       "      <th>dataset_features</th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>features</th>\n",
       "      <th>mdata_spatial_path</th>\n",
       "      <th>jsd</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>power0</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_3_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_3</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_3.h5mu</td>\n",
       "      <td>0.447103</td>\n",
       "      <td>0.095370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>power0</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_1_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_1</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_1.h5mu</td>\n",
       "      <td>0.627900</td>\n",
       "      <td>0.159803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>power0</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_4_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_4</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_4.h5mu</td>\n",
       "      <td>0.518654</td>\n",
       "      <td>0.116674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>power0</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_2_highly_accessible</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_2</td>\n",
       "      <td>highly_accessible</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_2.h5mu</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.081335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/vol/storage/data/deconvolution_results/test2/...</td>\n",
       "      <td>power0</td>\n",
       "      <td>atac</td>\n",
       "      <td>Heart_3_highly_variable</td>\n",
       "      <td>tangram</td>\n",
       "      <td>Heart_3</td>\n",
       "      <td>highly_variable</td>\n",
       "      <td>/vol/storage/data/simulations/test/Heart_3.h5mu</td>\n",
       "      <td>0.440834</td>\n",
       "      <td>0.093058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path   power modality  \\\n",
       "0  /vol/storage/data/deconvolution_results/test2/...  power0     atac   \n",
       "1  /vol/storage/data/deconvolution_results/test2/...  power0     atac   \n",
       "2  /vol/storage/data/deconvolution_results/test2/...  power0     atac   \n",
       "3  /vol/storage/data/deconvolution_results/test2/...  power0     atac   \n",
       "4  /vol/storage/data/deconvolution_results/test2/...  power0     atac   \n",
       "\n",
       "            dataset_features   method  dataset           features  \\\n",
       "0  Heart_3_highly_accessible  tangram  Heart_3  highly_accessible   \n",
       "1  Heart_1_highly_accessible  tangram  Heart_1  highly_accessible   \n",
       "2    Heart_4_highly_variable  tangram  Heart_4    highly_variable   \n",
       "3  Heart_2_highly_accessible  tangram  Heart_2  highly_accessible   \n",
       "4    Heart_3_highly_variable  tangram  Heart_3    highly_variable   \n",
       "\n",
       "                                mdata_spatial_path       jsd      rmse  \n",
       "0  /vol/storage/data/simulations/test/Heart_3.h5mu  0.447103  0.095370  \n",
       "1  /vol/storage/data/simulations/test/Heart_1.h5mu  0.627900  0.159803  \n",
       "2  /vol/storage/data/simulations/test/Heart_4.h5mu  0.518654  0.116674  \n",
       "3  /vol/storage/data/simulations/test/Heart_2.h5mu  0.441142  0.081335  \n",
       "4  /vol/storage/data/simulations/test/Heart_3.h5mu  0.440834  0.093058  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../results/tables/results_table_tangram_draw.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power   method   features           modality\n",
       "power0  tangram  highly_variable    rna         0.503227\n",
       "                 highly_accessible  atac        0.505794\n",
       "                 highly_variable    atac        0.506328\n",
       "power1  tangram  highly_variable    rna         0.560245\n",
       "                                    atac        0.569520\n",
       "                 highly_accessible  atac        0.572636\n",
       "power2  tangram  highly_variable    rna         0.615094\n",
       "                                    atac        0.630930\n",
       "                 highly_accessible  atac        0.635952\n",
       "power3  tangram  highly_variable    rna         0.657895\n",
       "                                    atac        0.677503\n",
       "                 highly_accessible  atac        0.685836\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['power','method', 'features', 'modality'])[['jsd']].mean().sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power   method   features           modality\n",
       "power0  tangram  highly_variable    rna         0.110739\n",
       "                                    atac        0.112276\n",
       "                 highly_accessible  atac        0.113434\n",
       "power1  tangram  highly_variable    rna         0.124068\n",
       "                                    atac        0.126064\n",
       "                 highly_accessible  atac        0.127212\n",
       "power2  tangram  highly_variable    rna         0.138309\n",
       "                                    atac        0.141058\n",
       "                 highly_accessible  atac        0.142221\n",
       "power3  tangram  highly_variable    rna         0.149177\n",
       "                                    atac        0.153051\n",
       "                 highly_accessible  atac        0.154847\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['power','method', 'features', 'modality'])[['rmse']].mean().sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell2loc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
